{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# transformers-ipfs Example in Google Colab\n",
        "\n",
        "This notebook demonstrates how to use Hugging Face Transformers with IPFS models using the transformers-ipfs integration.\n",
        "\n",
        "## Step 1: Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install transformers, PyTorch, and transformers-ipfs\n",
        "!pip install transformers torch transformers-ipfs --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Activate IPFS Integration\n",
        "\n",
        "In most environments, you would use `transformers-ipfs activate`, but in Google Colab we need to apply the patch explicitly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard activation approach:\n",
        "# ~# transformers-ipfs activate\n",
        "\n",
        "# Google Colab activation approach:\n",
        "import transformers_ipfs; transformers_ipfs.activate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load and Use an IPFS-hosted Model\n",
        "\n",
        "Now we can load models directly from IPFS using their CID:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load model directly from IPFS\n",
        "model_uri = \"ipfs://bafybeichqdarufyutqc7yd43k77fkxbmeuhhetbihd3g32ghcqvijp6fxi\"\n",
        "# Equivalent HuggingFace model: model_uri = \"riturajpandey739/gpt2-sentiment-analysis-tweets\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_uri)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_uri)\n",
        "\n",
        "LABELS = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "    sentiment = LABELS[predicted_class]\n",
        "    confidence = float(probabilities[0][predicted_class])\n",
        "    return sentiment, confidence\n",
        "\n",
        "example_tweets = [\n",
        "    \"I absolutely love this new update! The features are amazing! ðŸ˜Š\",\n",
        "    \"This is the worst service I've ever experienced. Very disappointed. ðŸ˜ \",\n",
        "    \"The weather is nice today, perfect for a walk in the park!\",\n",
        "    \"This product is not worth the money, don't buy it ðŸ‘Ž\"\n",
        "]\n",
        "\n",
        "for tweet in example_tweets:\n",
        "    sentiment, confidence = analyze_sentiment(tweet)\n",
        "    print(f\"Tweet: {tweet}\")\n",
        "    print(f\"Sentiment: {sentiment} (confidence: {confidence:.2%})\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How It Works\n",
        "\n",
        "The `transformers-ipfs` package patches the Hugging Face Transformers library to:\n",
        "\n",
        "1. Recognize `ipfs://` URIs as valid model identifiers\n",
        "2. Download model files from IPFS nodes or gateways\n",
        "3. Cache models locally for faster loading in subsequent runs\n",
        "\n",
        "This allows you to load models from a decentralized network without changing any of your existing code!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
